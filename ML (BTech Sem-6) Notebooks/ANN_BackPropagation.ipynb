{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_BackPropagation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPnOZoyXysY7nJ9DfVhUPeo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"MSx9c11tGT3f","executionInfo":{"status":"ok","timestamp":1618838352015,"user_tz":-330,"elapsed":3651,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fw7-PIGKG-6I","executionInfo":{"status":"ok","timestamp":1618838352744,"user_tz":-330,"elapsed":4375,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["w1 = tf.Variable(5.)\n","w2 = tf.Variable(8.)\n","b = tf.Variable(-2.)\n","lr = tf.Variable(0.02)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8kjm-l_HAHa","executionInfo":{"status":"ok","timestamp":1618838352746,"user_tz":-330,"elapsed":4373,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["@tf.function\n","def y_hat(x1,x2):\n","    return w1*x1 + w2*x2 + b"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HAr92nJHMjV","executionInfo":{"status":"ok","timestamp":1618838352747,"user_tz":-330,"elapsed":4371,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["@tf.function\n","def loss_function(y, x1, x2):\n","    return (y-y_hat(x1,x2))**2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4VcU9IZHSMz","executionInfo":{"status":"ok","timestamp":1618838352747,"user_tz":-330,"elapsed":4368,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["def update_weight(delta_w1,delta_w2,delta_b):\n","    w1.assign_sub(delta_w1*lr)\n","    w2.assign_sub(delta_w2*lr)\n","    b.assign_sub(delta_b*lr)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsU7pFimHVSQ","executionInfo":{"status":"ok","timestamp":1618838352748,"user_tz":-330,"elapsed":4366,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}}},"source":["X1 = [2,1,3,-1,-3,1,2]\n","X2 = [3,1,-1,1,-2,1,2]\n","Y = [18,10,8,6,-7,10,15]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hw3TAfGIHdia","executionInfo":{"status":"ok","timestamp":1618838356759,"user_tz":-330,"elapsed":8368,"user":{"displayName":"Vivek Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64","userId":"16604758865318092560"}},"outputId":"d6fc73c7-4fe0-482e-d4f4-d5009c042dd5"},"source":["with tf.GradientTape(persistent=True) as tape:\n","    print(\"Initially : W1 = \"+str(w1.numpy()) + \", W2 = \"+str(w2.numpy()) + \", b = \"+str(b.numpy()))\n","    for i in range(len(X1)):\n","        print(\"Starting Iteration no. \"+str(i+1)+ \"..\")\n","        y = tf.Variable(float(Y[i]))\n","        x1 = tf.Variable(float(X1[i]))\n","        x2 = tf.Variable(float(X2[i]))\n","\n","        #initializing the loss function with next set of training set\n","        loss = loss_function(y,x1,x2)\n","        \n","        # finding the gradient of loss function w.r.t. w1,w2 and b\n","        gradients = tape.gradient(loss, [w1,w2,b])\n","        print(\"Gradient : W1 = \"+str(w1.numpy()) + \", W2 = \"+str(w2.numpy()) + \", b = \"+str(b.numpy()))\n","        \n","        update_weight(*gradients)\n","        print(\"New Updated weights : W1 = \"+str(w1.numpy()) + \", W2 = \"+str(w2.numpy()) + \", b = \"+str(b.numpy()))\n","        print(\"Finished Iteration : \" + str(i+1))\n","\n","    del tape"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Initially : W1 = 5.0, W2 = 8.0, b = -2.0\n","Starting Iteration no. 1..\n","WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n","Gradient : W1 = 5.0, W2 = 8.0, b = -2.0\n","New Updated weights : W1 = 3.88, W2 = 6.32, b = -2.56\n","Finished Iteration : 1\n","Starting Iteration no. 2..\n","Gradient : W1 = 3.88, W2 = 6.32, b = -2.56\n","New Updated weights : W1 = 3.9744, W2 = 6.4144, b = -2.4656\n","Finished Iteration : 2\n","Starting Iteration no. 3..\n","Gradient : W1 = 3.9744, W2 = 6.4144, b = -2.4656\n","New Updated weights : W1 = 4.569216, W2 = 6.2161283, b = -2.267328\n","Finished Iteration : 3\n","Starting Iteration no. 4..\n","Gradient : W1 = 4.569216, W2 = 6.2161283, b = -2.267328\n","New Updated weights : W1 = 4.304399, W2 = 6.480945, b = -2.0025115\n","Finished Iteration : 4\n","Starting Iteration no. 5..\n","WARNING:tensorflow:5 out of the last 5 calls to <function loss_function at 0x7fd3251f6170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Gradient : W1 = 4.304399, W2 = 6.480945, b = -2.0025115\n","New Updated weights : W1 = 1.7990873, W2 = 4.8107376, b = -1.1674076\n","Finished Iteration : 5\n","Starting Iteration no. 6..\n","WARNING:tensorflow:6 out of the last 6 calls to <function loss_function at 0x7fd3251f6170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Gradient : W1 = 1.7990873, W2 = 4.8107376, b = -1.1674076\n","New Updated weights : W1 = 1.9813906, W2 = 4.993041, b = -0.9851043\n","Finished Iteration : 6\n","Starting Iteration no. 7..\n","WARNING:tensorflow:7 out of the last 7 calls to <function loss_function at 0x7fd3251f6170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Gradient : W1 = 1.9813906, W2 = 4.993041, b = -0.9851043\n","New Updated weights : W1 = 2.14429, W2 = 5.1559405, b = -0.9036547\n","Finished Iteration : 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qKg7Po7-SMih"},"source":[""],"execution_count":null,"outputs":[]}]}