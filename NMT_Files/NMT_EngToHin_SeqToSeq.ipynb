{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1628762348522,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "4Qk75wWsIMxX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3454,
     "status": "ok",
     "timestamp": 1628762352544,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "v1I8RYmVIWsz"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2271,
     "status": "ok",
     "timestamp": 1628762354813,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "kHYd3geM2C9e"
   },
   "outputs": [],
   "source": [
    "lines = pd.read_csv(\"Hindi_English_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1628762355860,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "ujGykg2L2tFB",
    "outputId": "82d4dab7-49e9-47e7-e54e-a7d7b8e2be5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['source']=='ted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1628762355864,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "qGDn7e0H20I7",
    "outputId": "ea83b4d8-a446-40e4-e561-0ed58122b7bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ted</td>\n",
       "      <td>This changed slowly</td>\n",
       "      <td>धीरे धीरे ये सब बदला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ted</td>\n",
       "      <td>were being produced.</td>\n",
       "      <td>उत्पन्न नहीं कि जाती थी.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ted</td>\n",
       "      <td>And you can see, this LED is going to glow.</td>\n",
       "      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ted</td>\n",
       "      <td>to turn on the lights or to bring him a glass ...</td>\n",
       "      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ted</td>\n",
       "      <td>Can you imagine saying that?</td>\n",
       "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ted</td>\n",
       "      <td>Three: this is a good road in - right near whe...</td>\n",
       "      <td>तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ted</td>\n",
       "      <td>What's going on?”</td>\n",
       "      <td>क्या हो रहा है ये?”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ted</td>\n",
       "      <td>There are also financial reforms in rural China.</td>\n",
       "      <td>ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ted</td>\n",
       "      <td>the family planning started in Vietnam and the...</td>\n",
       "      <td>वियतनाम में परिवार योजना शुरू हो गई और उनके पर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ted</td>\n",
       "      <td>I mean, at that time, trust me,</td>\n",
       "      <td>मेरा मतलब, उस समय, सही मानिए,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ted</td>\n",
       "      <td>Not only that,</td>\n",
       "      <td>बस वही नहीं,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ted</td>\n",
       "      <td>humans destroyed the commons that they depende...</td>\n",
       "      <td>मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ted</td>\n",
       "      <td>Almost goes to E, but otherwise the play would...</td>\n",
       "      <td>रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ted</td>\n",
       "      <td>So I want to share with you a couple key insights</td>\n",
       "      <td>मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ted</td>\n",
       "      <td>Many countries in the [unclear], they need leg...</td>\n",
       "      <td>[अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चा...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted         I'd like to tell you about one such child,   \n",
       "3     ted  what we really mean is that they're bad at not...   \n",
       "7     ted   And who are we to say, even, that they are wrong   \n",
       "13    ted                   So there is some sort of justice   \n",
       "23    ted                                This changed slowly   \n",
       "26    ted                               were being produced.   \n",
       "30    ted        And you can see, this LED is going to glow.   \n",
       "32    ted  to turn on the lights or to bring him a glass ...   \n",
       "35    ted                       Can you imagine saying that?   \n",
       "37    ted  Three: this is a good road in - right near whe...   \n",
       "39    ted                                  What's going on?”   \n",
       "42    ted   There are also financial reforms in rural China.   \n",
       "49    ted  the family planning started in Vietnam and the...   \n",
       "51    ted                    I mean, at that time, trust me,   \n",
       "53    ted                                     Not only that,   \n",
       "55    ted  humans destroyed the commons that they depende...   \n",
       "56    ted  Almost goes to E, but otherwise the play would...   \n",
       "63    ted  So I want to share with you a couple key insights   \n",
       "66    ted  Many countries in the [unclear], they need leg...   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
       "13                                   तो वहाँ न्याय है  \n",
       "23                               धीरे धीरे ये सब बदला  \n",
       "26                           उत्पन्न नहीं कि जाती थी.  \n",
       "30       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।  \n",
       "32    लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,  \n",
       "35                       क्या आप ये कल्पना कर सकते है  \n",
       "37  तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षा...  \n",
       "39                                क्या हो रहा है ये?”  \n",
       "42          ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।  \n",
       "49  वियतनाम में परिवार योजना शुरू हो गई और उनके पर...  \n",
       "51                      मेरा मतलब, उस समय, सही मानिए,  \n",
       "53                                       बस वही नहीं,  \n",
       "55  मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन...  \n",
       "56  रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़...  \n",
       "63      मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ  \n",
       "66  [अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चा...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1628762355865,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "Ylg-zcbf21ry",
    "outputId": "6fe462bf-75ba-4169-a039-5f1438f18bf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628762355866,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "vkZ251gZ25wz"
   },
   "outputs": [],
   "source": [
    "lines = lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628762355867,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "IWBnKaYW27ty"
   },
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628762355870,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "kVG--N_w3ABs"
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628762355871,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "qvr_H2Ib3FH_"
   },
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628762355872,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "O46X8kNW3Iv4"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1628762356499,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "VGH9yyl_3K5N"
   },
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1628762356501,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "4pMYnOgg3P5m"
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1628762356502,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "osPdOZiP3TKy",
    "outputId": "c8c017fc-4886-4598-9497-00f202212045"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>and who are we to say even that they are wrong</td>\n",
       "      <td>START_ और हम होते कौन हैं यह कहने भी वाले कि व...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>so there is some sort of justice</td>\n",
       "      <td>START_ तो वहाँ न्याय है _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted           id like to tell you about one such child   \n",
       "3     ted  what we really mean is that theyre bad at not ...   \n",
       "7     ted     and who are we to say even that they are wrong   \n",
       "13    ted                   so there is some sort of justice   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...  \n",
       "1   START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...  \n",
       "3   START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...  \n",
       "7   START_ और हम होते कौन हैं यह कहने भी वाले कि व...  \n",
       "13                       START_ तो वहाँ न्याय है _END  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1628762356504,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "i-3aLoYV3U8w"
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1628762356506,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "3bwoxPfp3ZTi",
    "outputId": "b449cb6b-a0c3-4fe8-aa96-2c2dab6e0f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1628762356507,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "0tclnI103d0E",
    "outputId": "4af366ae-8e90-4f5c-f118-2ef19146ff62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1628762356508,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "z0JfUv2q3oaW"
   },
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1628762356509,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "hvde6J_V3tLn",
    "outputId": "60374835-31dd-41cb-f4af-218aa711411c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>and who are we to say even that they are wrong</td>\n",
       "      <td>START_ और हम होते कौन हैं यह कहने भी वाले कि व...</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>so there is some sort of justice</td>\n",
       "      <td>START_ तो वहाँ न्याय है _END</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted           id like to tell you about one such child   \n",
       "3     ted  what we really mean is that theyre bad at not ...   \n",
       "7     ted     and who are we to say even that they are wrong   \n",
       "13    ted                   so there is some sort of justice   \n",
       "\n",
       "                                       hindi_sentence  length_eng_sentence  \\\n",
       "0   START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...                   12   \n",
       "1   START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...                    9   \n",
       "3   START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...                   12   \n",
       "7   START_ और हम होते कौन हैं यह कहने भी वाले कि व...                   11   \n",
       "13                       START_ तो वहाँ न्याय है _END                    7   \n",
       "\n",
       "    length_hin_sentence  \n",
       "0                    15  \n",
       "1                    13  \n",
       "3                    13  \n",
       "7                    15  \n",
       "13                    6  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1628762356510,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "sYq67Fig3u3b",
    "outputId": "e63119eb-9c80-4797-fe84-27f2c78e9c4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1628762356511,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "ZA_SNqs63w_i"
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1628762356513,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "zgjXm4Oz3zi4",
    "outputId": "d2ebf1a0-e60b-46fe-b3c0-2c7295d4cd90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38476, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1628762356517,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "iqa_gF_X37ti",
    "outputId": "3aa74e3c-90af-4751-e464-d710a9e927e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1628762357454,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "Zcm2fLad390O"
   },
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1628762357463,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "knMcNUkZ3_69",
    "outputId": "45a8143b-a38d-4de3-fbd6-4e7615d0cf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(max_length_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1628762357464,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "CQa4eNXf4Bt1",
    "outputId": "c18680c3-44df-4adc-f60e-b9178f7ae6fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17345, 22285)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1628762357465,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "kngx8vWK4DqR"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens += 1\n",
    "num_decoder_tokens += 1 #for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1628762357468,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "KZhDZcS34F79"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1628762357469,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "_-WC89eW4Hnp"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1628762357471,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "uepMRsOd4JmF",
    "outputId": "90d122ab-36d5-44b8-a6de-0febd29869c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92425</th>\n",
       "      <td>ted</td>\n",
       "      <td>and then another pair of legs we collaborated ...</td>\n",
       "      <td>START_ और फिर एक और जोडी़ टांगें जिन पर हमने ए...</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92555</th>\n",
       "      <td>ted</td>\n",
       "      <td>for you to get involved in something that will...</td>\n",
       "      <td>START_ जो आपको किसी ऐसी चीज़ में शामिल करेंगे ...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80383</th>\n",
       "      <td>ted</td>\n",
       "      <td>and reduce overall blood pressure</td>\n",
       "      <td>START_ और कुलमिलाकर रक्तचाप को घटाता है _END</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>ted</td>\n",
       "      <td>or if they get an extra ration of food</td>\n",
       "      <td>START_ अगर हफ्ते के आखिर में उन्हें _END</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59888</th>\n",
       "      <td>ted</td>\n",
       "      <td>sharmeen is actually here</td>\n",
       "      <td>START_ शारमीन वहाँ पर है। _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53722</th>\n",
       "      <td>ted</td>\n",
       "      <td>and then you can have all the nice stuff</td>\n",
       "      <td>START_ और तब आप इन सारी कलात्मक चीजों का आनन्द...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123158</th>\n",
       "      <td>ted</td>\n",
       "      <td>pipa is short for protectip</td>\n",
       "      <td>START_ पिपा pipa लघु रूप है protectip का _END</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93052</th>\n",
       "      <td>ted</td>\n",
       "      <td>and suddenly without realizing it</td>\n",
       "      <td>START_ और अचनाक आपको पता भी नहीं चला _END</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78289</th>\n",
       "      <td>ted</td>\n",
       "      <td>continuously producing identical people</td>\n",
       "      <td>START_ लगातार समान लोगों का निर्माण कर रहा हैं...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21013</th>\n",
       "      <td>ted</td>\n",
       "      <td>she had a girlfriend who had heard about this ...</td>\n",
       "      <td>START_ उसकी एक सहेली थी जिसने जामी बोरा नामक स...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "92425     ted  and then another pair of legs we collaborated ...   \n",
       "92555     ted  for you to get involved in something that will...   \n",
       "80383     ted                  and reduce overall blood pressure   \n",
       "81405     ted             or if they get an extra ration of food   \n",
       "59888     ted                          sharmeen is actually here   \n",
       "53722     ted           and then you can have all the nice stuff   \n",
       "123158    ted                        pipa is short for protectip   \n",
       "93052     ted                  and suddenly without realizing it   \n",
       "78289     ted            continuously producing identical people   \n",
       "21013     ted  she had a girlfriend who had heard about this ...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "92425   START_ और फिर एक और जोडी़ टांगें जिन पर हमने ए...   \n",
       "92555   START_ जो आपको किसी ऐसी चीज़ में शामिल करेंगे ...   \n",
       "80383        START_ और कुलमिलाकर रक्तचाप को घटाता है _END   \n",
       "81405            START_ अगर हफ्ते के आखिर में उन्हें _END   \n",
       "59888                      START_ शारमीन वहाँ पर है। _END   \n",
       "53722   START_ और तब आप इन सारी कलात्मक चीजों का आनन्द...   \n",
       "123158      START_ पिपा pipa लघु रूप है protectip का _END   \n",
       "93052           START_ और अचनाक आपको पता भी नहीं चला _END   \n",
       "78289   START_ लगातार समान लोगों का निर्माण कर रहा हैं...   \n",
       "21013   START_ उसकी एक सहेली थी जिसने जामी बोरा नामक स...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "92425                    11                   18  \n",
       "92555                    11                   11  \n",
       "80383                     5                    8  \n",
       "81405                     9                    8  \n",
       "59888                     4                    6  \n",
       "53722                     9                   14  \n",
       "123158                    5                    9  \n",
       "93052                     5                    9  \n",
       "78289                     4                   10  \n",
       "21013                    12                   16  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1628762357472,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "lnSjD8IG4Mll",
    "outputId": "a37f066e-e7d0-46d9-e0ff-bcf41e7fce03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30780,), (7696,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1628762357473,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "Nb1s_uY44XPh"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1628762357474,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "m6PTiFUK4dgX"
   },
   "outputs": [],
   "source": [
    "latent_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1628762359135,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "KohgoQ4H4fzd"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 2241,
     "status": "ok",
     "timestamp": 1628762361366,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "7BDB-gJF4ij-"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1628762361366,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "IcSMT1am4mjO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1628762361367,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "0_8I55fN4q8t",
    "outputId": "8985989f-1a26-4738-dd5f-754ddd421db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    5203800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    6685800     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 22286)  6708086     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 20,040,086\n",
      "Trainable params: 20,040,086\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1628762361368,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "3m2Jwuil4t6-"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "executionInfo": {
     "elapsed": 9344,
     "status": "error",
     "timestamp": 1628762489446,
     "user": {
      "displayName": "Vivek Parmar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQvSN1U7ajex8Lg2-3ghFFG69J1XGJPvy5DaAQLQ=s64",
      "userId": "16604758865318092560"
     },
     "user_tz": -330
    },
    "id": "KLcnmzKY49Lk",
    "outputId": "801e5bc8-34a0-4070-8d11-b64abf29a82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "240/240 [==============================] - 716s 3s/step - loss: 2.9517 - val_loss: 2.7611\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 543s 2s/step - loss: 2.6298 - val_loss: 2.5831\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 2.4702 - val_loss: 2.5064\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 521s 2s/step - loss: 2.3538 - val_loss: 2.4482\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 524s 2s/step - loss: 2.2537 - val_loss: 2.4091\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 2.1625 - val_loss: 2.3881\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 2.0806 - val_loss: 2.3591\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 2.0053 - val_loss: 2.3476\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.9341 - val_loss: 2.3501\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 1.8664 - val_loss: 2.3377\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.8021 - val_loss: 2.3397\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.7399 - val_loss: 2.3433\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.6806 - val_loss: 2.3566\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.6216 - val_loss: 2.3715\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.5653 - val_loss: 2.3896\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.5102 - val_loss: 2.4027\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.4578 - val_loss: 2.4154\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 568s 2s/step - loss: 1.4054 - val_loss: 2.4323\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 530s 2s/step - loss: 1.3574 - val_loss: 2.4516\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 524s 2s/step - loss: 1.3086 - val_loss: 2.4794\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 1.2620 - val_loss: 2.5000\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.2163 - val_loss: 2.5238\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.1728 - val_loss: 2.5443\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 1.1315 - val_loss: 2.5692\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 1.0902 - val_loss: 2.5911\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 1.0525 - val_loss: 2.6102\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 1.0140 - val_loss: 2.6366\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 529s 2s/step - loss: 0.9787 - val_loss: 2.6566\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 539s 2s/step - loss: 0.9430 - val_loss: 2.6808\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 540s 2s/step - loss: 0.9112 - val_loss: 2.7006\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 539s 2s/step - loss: 0.8798 - val_loss: 2.7329\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 538s 2s/step - loss: 0.8489 - val_loss: 2.7575\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 539s 2s/step - loss: 0.8204 - val_loss: 2.7829\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 538s 2s/step - loss: 0.7927 - val_loss: 2.8030\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.7650 - val_loss: 2.8256\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.7403 - val_loss: 2.8436\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.7156 - val_loss: 2.8636\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.6933 - val_loss: 2.8891\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 524s 2s/step - loss: 0.6718 - val_loss: 2.9092\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.6506 - val_loss: 2.9252\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.6325 - val_loss: 2.9448\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 0.6134 - val_loss: 2.9511\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.5950 - val_loss: 2.9671\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.5774 - val_loss: 2.9892\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 0.5608 - val_loss: 3.0084\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.5448 - val_loss: 3.0246\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.5293 - val_loss: 3.0284\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 0.5143 - val_loss: 3.0453\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 522s 2s/step - loss: 0.5000 - val_loss: 3.0600\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 523s 2s/step - loss: 0.4864 - val_loss: 3.0785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa87986c610>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ucLw8JNK_CaT"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "PirdBH1UNrw9"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dcTNWOG4Nw7p"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ZkLqbB_QN3mg"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Ng22RlMAOODG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: just like an adventurers cap\n",
      "Actual Hindi Translation:  जैसे किसी साहसिक कार्यक्रम पर जाने वाले की टोपी होती है। \n",
      "Predicted Hindi Translation:  जैसे किसी ऊपर की पैसे या कम कम लिए वह कॉलेज नही\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NMT_EngToHin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-15 21:17:48.005554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-15 21:17:48.005632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras 'NMT_EngToHin.h5' 'NMT_EngToHin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPi5VQwEfA4ZeBwXCowQO53",
   "collapsed_sections": [],
   "mount_file_id": "1se6lQDrh4SGnUj8fPOR04b45IK_Baz_D",
   "name": "NMT_English_to_Hindi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
