{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_EngToHin_gloVe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uWn1l1pWuhc",
        "outputId": "d7715bc4-2f55-49f5-e360-ace189306f04"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0Etzmmbd8Ee"
      },
      "source": [
        "from builtins import range, input\n",
        "import os, sys\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K\n",
        "from keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrluNo7vt4p6"
      },
      "source": [
        "lines = pd.read_csv(\"/content/drive/MyDrive/NMT_Data/Hindi_English_Corpus.csv\",encoding='utf-8')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXe61L4uQ6y"
      },
      "source": [
        "lines=lines[lines['source']=='ted']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt4zC5b88VM4"
      },
      "source": [
        "engSentences = lines['english_sentence']\n",
        "hinSentences = lines['hindi_sentence']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtsJardouYag"
      },
      "source": [
        "engSentences = engSentences[:5000]\n",
        "hinSentences = hinSentences[:5000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veCPoApj_Yna",
        "outputId": "304dd61d-65f0-429d-aebc-486011d7fe7c"
      },
      "source": [
        "X, y = engSentences, hinSentences\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1,random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4500,), (500,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McdmYpEv-BvJ",
        "outputId": "dc390a82-0d55-4356-fdf3-72e0c40b48ca"
      },
      "source": [
        "#For training Data\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "target_texts_inputs = []\n",
        "\n",
        "#Converting to lowercase\n",
        "en_train = [line.lower() for line in X_train]\n",
        "hin_train = [line.lower() for line in y_train]\n",
        "\n",
        "NUM_SAMPLES = len(en_train)\n",
        "print(\"Sample train size:\",NUM_SAMPLES)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample train size: 4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NvpYekh-XP3"
      },
      "source": [
        "for lines in hin_train:\n",
        "    target_texts_inputs.append('<sos>'+\" \"+ lines)\n",
        "    \n",
        "for lines in hin_train:\n",
        "    target_texts.append(lines+ \" \" +'<eos>')\n",
        "    \n",
        "for lines in en_train:\n",
        "    input_texts.append(lines)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c920Yyu_-rRd"
      },
      "source": [
        "tokenizer_inputs = Tokenizer()\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "max_len_input = max(len(s) for s in input_sequences)\n",
        "\n",
        "tokenizer_outputs = Tokenizer(filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) \n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kqs0KBN_2z9"
      },
      "source": [
        "#For Testing Data\n",
        "input_texts_test = []\n",
        "target_texts_test = [] \n",
        "target_texts_inputs_test = []\n",
        "\n",
        "en_test = [line.lower() for line in X_test]\n",
        "hin_test = [line.lower() for line in y_test]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tTo_Ln9AI5G"
      },
      "source": [
        "for lines in hin_test:\n",
        "    target_texts_inputs_test.append('<sos>'+\" \"+ lines)\n",
        "    \n",
        "for lines in hin_test:\n",
        "    target_texts_test.append(lines+ \" \" +'<eos>')\n",
        "    \n",
        "for lines in en_test:\n",
        "    input_texts_test.append(lines)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lL8-DoWAXz1"
      },
      "source": [
        "input_sequences_test = tokenizer_inputs.texts_to_sequences(input_texts_test)\n",
        "\n",
        "target_sequences_test = tokenizer_outputs.texts_to_sequences(target_texts_test)\n",
        "target_sequences_inputs_test = tokenizer_outputs.texts_to_sequences(target_texts_inputs_test)\n",
        "\n",
        "encoder_inputs_test = pad_sequences(input_sequences_test, maxlen=max_len_input)\n",
        "decoder_inputs_test = pad_sequences(target_sequences_inputs_test, maxlen=max_len_target, padding='post')\n",
        "decoder_targets_test = pad_sequences(target_sequences_test, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tonvKTvgAxZz"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "EPOCHS = 50\n",
        "LATENT_DIM = 256\n",
        "LATENT_DIM_DECODER = 256 \n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQo-nOc1ieAB"
      },
      "source": [
        "embeddings_index = {}\n",
        "with open(os.path.join(\"/content/drive/MyDrive/NMT_Data/gloveData.txt\".format(EMBEDDING_DIM)), encoding=\"utf8\") as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = vec"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFs0rTg9jJpd"
      },
      "source": [
        "num_words = len(word2idx_inputs) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < num_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCY0TbOkmni"
      },
      "source": [
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e / s"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-TBXJrlCqY"
      },
      "source": [
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFeha08hBZ12"
      },
      "source": [
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIO8OTpxtxbZ"
      },
      "source": [
        "#encoder\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = Bidirectional(LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True, dropout=0.2\n",
        "))\n",
        "encoder_outputs = encoder(x)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayXQNvdLuaGw"
      },
      "source": [
        "#Decoder\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sv-flyOuozZ"
      },
      "source": [
        "attn_repeat_layer = RepeatVector(max_len_input)\n",
        "attn_concat_layer = Concatenate(axis=-1)\n",
        "attn_dense1 = Dense(10, activation='tanh')\n",
        "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYV4eFhgu8gj"
      },
      "source": [
        "def one_step_attention(h, st_1):\n",
        "  st_1 = attn_repeat_layer(st_1)\n",
        "  x = attn_concat_layer([h, st_1])\n",
        "  x = attn_dense1(x)\n",
        "  alphas = attn_dense2(x)\n",
        "  context = attn_dot([alphas, h])\n",
        "  return context"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8HoFG7RvLeY"
      },
      "source": [
        "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "\n",
        "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
        "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
        "context_last_word_concat_layer = Concatenate(axis=2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePkH9GWvO4W"
      },
      "source": [
        "# s, c will be re-assigned in each iteration of the loop\n",
        "s = initial_s\n",
        "c = initial_c\n",
        "\n",
        "# collect outputs in a list at first\n",
        "outputs = []\n",
        "for t in range(max_len_target): # Ty times\n",
        "  # get the context using attention\n",
        "  context = one_step_attention(encoder_outputs, s)\n",
        "\n",
        "  # we need a different layer for each time step\n",
        "  selector = Lambda(lambda x: x[:, t:t+1])\n",
        "  xt = selector(decoder_inputs_x)\n",
        "  \n",
        "  # combine \n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "\n",
        "  # pass the combined [context, last word] into the LSTM\n",
        "  # along with [s, c]\n",
        "  # get the new [s, c] and output\n",
        "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
        "\n",
        "  # final dense layer to get next word prediction\n",
        "  decoder_outputs = decoder_dense(o)\n",
        "  outputs.append(decoder_outputs)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKrug9NvYvS"
      },
      "source": [
        "def stack_and_transpose(x):\n",
        "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
        "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
        "  return x\n",
        "\n",
        "# make it a layerx``\n",
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv7Xf2cgzm7l"
      },
      "source": [
        "model = Model(\n",
        "  inputs=[\n",
        "    encoder_inputs_placeholder,\n",
        "    decoder_inputs_placeholder,\n",
        "    initial_s, \n",
        "    initial_c,\n",
        "  ],\n",
        "  outputs=outputs\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6MDN9kdzrB6"
      },
      "source": [
        "learning_rate=0.001"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqiHL2UQzuY5"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate) ,loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66yUxPZlzz55",
        "outputId": "2b7ea03c-f44d-4978-82f4-e722f73b7f45"
      },
      "source": [
        "z = np.zeros((encoder_inputs.shape[0], LATENT_DIM_DECODER)) # initial [s, c]\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 161s 13s/step - loss: 7.9252 - accuracy: 0.5717 - val_loss: 5.2859 - val_accuracy: 0.6724\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 4.0459 - accuracy: 0.6658 - val_loss: 2.8694 - val_accuracy: 0.6724\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 91s 11s/step - loss: 2.8693 - accuracy: 0.6658 - val_loss: 2.8982 - val_accuracy: 0.6724\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.9288 - accuracy: 0.6658 - val_loss: 2.8657 - val_accuracy: 0.6724\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.8490 - accuracy: 0.6658 - val_loss: 2.8365 - val_accuracy: 0.6724\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.7933 - accuracy: 0.6658 - val_loss: 2.7843 - val_accuracy: 0.6724\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.7242 - accuracy: 0.6658 - val_loss: 2.7208 - val_accuracy: 0.6724\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.6616 - accuracy: 0.6658 - val_loss: 2.6588 - val_accuracy: 0.6724\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.6001 - accuracy: 0.6658 - val_loss: 2.6066 - val_accuracy: 0.6724\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 91s 11s/step - loss: 2.5498 - accuracy: 0.6658 - val_loss: 2.5643 - val_accuracy: 0.6724\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.5087 - accuracy: 0.6658 - val_loss: 2.5291 - val_accuracy: 0.6724\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.4707 - accuracy: 0.6658 - val_loss: 2.5111 - val_accuracy: 0.6724\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.4479 - accuracy: 0.6658 - val_loss: 2.5086 - val_accuracy: 0.6724\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.4470 - accuracy: 0.6658 - val_loss: 2.4696 - val_accuracy: 0.6724\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.4176 - accuracy: 0.6658 - val_loss: 2.4609 - val_accuracy: 0.6724\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.4022 - accuracy: 0.6658 - val_loss: 2.4647 - val_accuracy: 0.6724\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 90s 11s/step - loss: 2.3897 - accuracy: 0.6658 - val_loss: 2.4541 - val_accuracy: 0.6724\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.3761 - accuracy: 0.6658 - val_loss: 2.4529 - val_accuracy: 0.6724\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.3656 - accuracy: 0.6658 - val_loss: 2.4737 - val_accuracy: 0.6724\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.3658 - accuracy: 0.6658 - val_loss: 2.4362 - val_accuracy: 0.6724\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.3421 - accuracy: 0.6658 - val_loss: 2.4333 - val_accuracy: 0.6724\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.3349 - accuracy: 0.6658 - val_loss: 2.4241 - val_accuracy: 0.6724\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.3230 - accuracy: 0.6658 - val_loss: 2.4248 - val_accuracy: 0.6724\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 92s 12s/step - loss: 2.3179 - accuracy: 0.6658 - val_loss: 2.4194 - val_accuracy: 0.6724\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.3055 - accuracy: 0.6663 - val_loss: 2.4240 - val_accuracy: 0.6724\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.2942 - accuracy: 0.6667 - val_loss: 2.4238 - val_accuracy: 0.6771\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.2876 - accuracy: 0.6708 - val_loss: 2.4191 - val_accuracy: 0.6773\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.2802 - accuracy: 0.6710 - val_loss: 2.4195 - val_accuracy: 0.6773\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 2.2670 - accuracy: 0.6711 - val_loss: 2.4214 - val_accuracy: 0.6775\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 2.2571 - accuracy: 0.6713 - val_loss: 2.4217 - val_accuracy: 0.6776\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 94s 12s/step - loss: 2.2482 - accuracy: 0.6715 - val_loss: 2.4311 - val_accuracy: 0.6779\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 2.2435 - accuracy: 0.6714 - val_loss: 2.4247 - val_accuracy: 0.6777\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.2326 - accuracy: 0.6716 - val_loss: 2.4274 - val_accuracy: 0.6781\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 2.2230 - accuracy: 0.6718 - val_loss: 2.4237 - val_accuracy: 0.6781\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.2196 - accuracy: 0.6717 - val_loss: 2.4981 - val_accuracy: 0.6784\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.2534 - accuracy: 0.6720 - val_loss: 2.4256 - val_accuracy: 0.6783\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 89s 11s/step - loss: 2.2214 - accuracy: 0.6719 - val_loss: 2.4296 - val_accuracy: 0.6787\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 91s 11s/step - loss: 2.2141 - accuracy: 0.6737 - val_loss: 2.4382 - val_accuracy: 0.6748\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.2103 - accuracy: 0.6724 - val_loss: 2.4254 - val_accuracy: 0.6784\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.1926 - accuracy: 0.6731 - val_loss: 2.4402 - val_accuracy: 0.6785\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.1925 - accuracy: 0.6762 - val_loss: 2.4397 - val_accuracy: 0.6687\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1865 - accuracy: 0.6773 - val_loss: 2.4323 - val_accuracy: 0.6797\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1801 - accuracy: 0.6758 - val_loss: 2.4384 - val_accuracy: 0.6746\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1725 - accuracy: 0.6793 - val_loss: 2.4355 - val_accuracy: 0.6777\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 92s 12s/step - loss: 2.1673 - accuracy: 0.6810 - val_loss: 2.4378 - val_accuracy: 0.6772\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1658 - accuracy: 0.6817 - val_loss: 2.4390 - val_accuracy: 0.6707\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 88s 11s/step - loss: 2.1595 - accuracy: 0.6837 - val_loss: 2.4431 - val_accuracy: 0.6767\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1602 - accuracy: 0.6837 - val_loss: 2.4415 - val_accuracy: 0.6737\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 86s 11s/step - loss: 2.1510 - accuracy: 0.6847 - val_loss: 2.4430 - val_accuracy: 0.6739\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 87s 11s/step - loss: 2.1506 - accuracy: 0.6840 - val_loss: 2.4427 - val_accuracy: 0.6742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m98o-kDMONX3"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/NMT_Data/NMT_EngToHin_gloVe.h5\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AsAjXmbSI7Z"
      },
      "source": [
        "#\n",
        "#Modifying the model for Predictions\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
        "\n",
        "# next we define a T=1 decoder model\n",
        "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# no need to loop over attention steps this time because there is only one step\n",
        "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
        "\n",
        "# combine context with last word\n",
        "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
        "\n",
        "# lstm and final dense\n",
        "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
        "decoder_outputs = decoder_dense(o)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUR8QHyQSRLU"
      },
      "source": [
        "# create the model object\n",
        "decoder_model = Model(\n",
        "  inputs=[\n",
        "    decoder_inputs_single,\n",
        "    encoder_outputs_as_input,\n",
        "    initial_s, \n",
        "    initial_c\n",
        "  ],\n",
        "  outputs=[decoder_outputs, s, c]\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNV-LhuLST_D",
        "outputId": "e6fc4f7a-a522-4c18-a5a7-3eb34623e0b9"
      },
      "source": [
        "decoder_model.save(\"/content/drive/MyDrive/NMT_Data/enghin_decoder_gloVeModel.h5\")\n",
        "encoder_model.save(\"/content/drive/MyDrive/NMT_Data/enghin_encoder_gloVeModel.h5\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2B2Lx8ESYoX"
      },
      "source": [
        "dx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECXSR_jSea3"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  enc_out = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  \n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "\n",
        "  # [s, c] will be updated in each loop iteration\n",
        "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
        "\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "        \n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(o.flatten())\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzD9y4t1Smu3"
      },
      "source": [
        "test_actual_sentence=[]\n",
        "test_predicted_sentence=[]\n",
        "for i in range(len(en_test)):\n",
        "  \n",
        "  input_seq = encoder_inputs_test[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "\n",
        "  test_actual_sentence.append(target_texts_test[i])\n",
        "  test_predicted_sentence.append(translation)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-rSAM6bSpZC",
        "outputId": "8133e3f2-169c-4d34-eec4-3015827828fe"
      },
      "source": [
        "for i in np.random.randint(0,100,5):\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts_test[i])\n",
        "    print('Predicted translation:', test_predicted_sentence[i])\n",
        "    print('Actual translation:', target_texts_test[i])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: the dragon vis-a-vis the elephant.\n",
            "Predicted translation: और और के\n",
            "Actual translation: चीनी ड्रेगन और हिन्दुस्तानी हाथी का मुकाबला। <eos>\n",
            "-\n",
            "Input sentence: but if you're not a native speaker,\n",
            "Predicted translation: और और के के\n",
            "Actual translation: मगर यदि आप इंगलिश के मूल-वक्ता नहीं हैं, <eos>\n",
            "-\n",
            "Input sentence: and we come to work when we don't feel like it,\n",
            "Predicted translation: और और और के के के के\n",
            "Actual translation: और हम तब भी क्लास जाते हैं जब हमारा बिल्कुल मन नहीं होता, <eos>\n",
            "-\n",
            "Input sentence: for our entire lives.\n",
            "Predicted translation: और और\n",
            "Actual translation: अपनी पूरी ज़िंदगी. <eos>\n",
            "-\n",
            "Input sentence: well, i do.\n",
            "Predicted translation: और और\n",
            "Actual translation: खैर, मैं करता हूँ <eos>\n"
          ]
        }
      ]
    }
  ]
}